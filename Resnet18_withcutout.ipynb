{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet18v1_cutout.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrrahul011/EIP-Session-4/blob/master/Resnet18_withcutout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixJKPZ8RfuVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import MaxPooling2D, AveragePooling2D, Input, Flatten,GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsnWiVHxf_dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training params.\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "data_augmentation = True\n",
        "#random_erasing = True\n",
        "#pixel_level = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Lhm3XXwgD3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network architecture params.\n",
        "num_classes = 10\n",
        "num_filters = 16\n",
        "num_blocks = 4\n",
        "num_sub_blocks = 2\n",
        "use_max_pool = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzeyr1KogIGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjW2saRegLu_",
        "colab_type": "code",
        "outputId": "71510776-08a6-45e3-f2ac-3f81a022b19e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Input image dimensions.\n",
        "# We assume data format \"channels_last\".\n",
        "img_rows = x_train.shape[1]\n",
        "img_cols = x_train.shape[2]\n",
        "channels = x_train.shape[3]\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    img_rows = x_train.shape[2]\n",
        "    img_cols = x_train.shape[3]\n",
        "    channels = x_train.shape[1]\n",
        "    x_train = x_train.reshape(x_train.shape[0], channels, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], channels, img_rows, img_cols)\n",
        "    input_shape = (channels, img_rows, img_cols)\n",
        "else:\n",
        "    img_rows = x_train.shape[1]\n",
        "    img_cols = x_train.shape[2]\n",
        "    channels = x_train.shape[3]\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, channels)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, channels)\n",
        "    input_shape = (img_rows, img_cols, channels)\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ3tPD8mgQSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcxIzJMXgSf4",
        "colab_type": "code",
        "outputId": "f07601e6-41a7-4385-8d0d-3515e4c1600a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Network architecture params.\n",
        "num_classes = 10\n",
        "num_filters = 16\n",
        "num_blocks = 4\n",
        "num_sub_blocks = 2\n",
        "use_max_pool = False\n",
        "\n",
        "# Start model definition.\n",
        "inputs = Input(shape=input_shape)\n",
        "x = Conv2D(num_filters,\n",
        "           kernel_size=3,\n",
        "           padding='same',\n",
        "           strides=1,\n",
        "           kernel_initializer='he_normal',\n",
        "           kernel_regularizer=l2(1e-4))(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "# Orig paper uses max pool after 1st conv.\n",
        "# Reaches up 87% acc if use_max_pool = True.\n",
        "# Cifar10 images are already too small at 32x32 to be maxpooled. So, we skip.\n",
        "#if use_max_pool:\n",
        "#    x = MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
        "#    num_blocks = 3\n",
        "\n",
        "# Instantiate convolutional base (stack of blocks).\n",
        "for i in range(num_blocks):\n",
        "    for j in range(num_sub_blocks-1):\n",
        "        strides = 1\n",
        "        #is_first_layer_but_not_first_block = j == 0 and i > 0\n",
        "        #if is_first_layer_but_not_first_block:\n",
        "        if (j == 0 and i>0):\n",
        "            strides = 2\n",
        "        y = Conv2D(num_filters,\n",
        "                   kernel_size=3,\n",
        "                   padding='same',\n",
        "                   strides=strides,\n",
        "                   kernel_initializer='he_normal',\n",
        "                   kernel_regularizer=l2(1e-4))(x)\n",
        "        y = BatchNormalization()(y)\n",
        "        y = Activation('relu')(y)\n",
        "        y = Conv2D(num_filters,\n",
        "                   kernel_size=3,\n",
        "                   padding='same',\n",
        "                   kernel_initializer='he_normal',\n",
        "                   kernel_regularizer=l2(1e-4))(y)\n",
        "        y = BatchNormalization()(y)\n",
        "        #if is_first_layer_but_not_first_block:\n",
        "        if (j == 0 and i>0):\n",
        "            x = Conv2D(num_filters,\n",
        "                       kernel_size=1,\n",
        "                       padding='same',\n",
        "                       strides=2,\n",
        "                       kernel_initializer='he_normal',\n",
        "                       kernel_regularizer=l2(1e-4))(x)\n",
        "        x = keras.layers.add([x, y])\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    num_filters = 2 * num_filters\n",
        "\n",
        "# Add classifier on top.\n",
        "x = Conv2D(10,1)(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "#x = AveragePooling2D(pool_size=4)(x)\n",
        "#y = Flatten()(x)\n",
        "outputs = Dense(num_classes,\n",
        "                activation='softmax',\n",
        "                kernel_initializer='he_normal')(x)\n",
        "# Instantiate and compile model.\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr = 0.001),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 32)   544         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 32)   0           conv2d_6[0][0]                   \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 32)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 8, 8, 64)     18496       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 8, 8, 64)     256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 8, 8, 64)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 8, 8, 64)     36928       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 8, 8, 64)     2112        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 8, 8, 64)     256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 8, 8, 64)     0           conv2d_9[0][0]                   \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 8, 8, 64)     0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 4, 4, 128)    73856       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 4, 4, 128)    512         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 4, 4, 128)    0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 4, 4, 128)    147584      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 4, 4, 128)    8320        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 4, 4, 128)    512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 4, 4, 128)    0           conv2d_12[0][0]                  \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 4, 4, 128)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 4, 4, 10)     1290        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 10)           0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 310,200\n",
            "Trainable params: 309,208\n",
            "Non-trainable params: 992\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8U6TW8DrMSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_resnet_model.h5'\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate decaying.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "callbacks = [checkpoint, lr_reducer]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwD4EEmvy5gd",
        "colab_type": "code",
        "outputId": "55719753-374b-45d9-9051-65fe7c1ab2bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "def cutout(img):\n",
        "    MAX_CUTS = 2  # chance to get more cuts\n",
        "    MAX_LENGTH_MULTIPLIER = 5  # change to get larger cuts ; 16 for cifar 10, 8 for cifar 100\n",
        "\n",
        "    height = img.shape[1]\n",
        "    width = img.shape[2]\n",
        "\n",
        "    # normalize before adding the mask\n",
        "    mean = img.mean(keepdims=True)\n",
        "    img -= mean\n",
        "\n",
        "    mask = np.ones((height, width), np.float32)\n",
        "    nb_cuts = np.random.randint(0, MAX_CUTS + 1)\n",
        "\n",
        "    for i in range(nb_cuts):\n",
        "        y = np.random.randint(height)\n",
        "        x = np.random.randint(width)\n",
        "        length = 4 * np.random.randint(1, MAX_LENGTH_MULTIPLIER + 1)\n",
        "\n",
        "        y1 = np.clip(y - length // 2, 0, height)\n",
        "        y2 = np.clip(y + length // 2, 0, height)\n",
        "        x1 = np.clip(x - length // 2, 0, width)\n",
        "        x2 = np.clip(x + length // 2, 0, width)\n",
        "\n",
        "        mask[y1: y2, x1: x2] = 0.\n",
        "\n",
        "    # apply mask\n",
        "    img = img * mask\n",
        "\n",
        "    # denormalize\n",
        "    img += mean\n",
        "\n",
        "    return img\n",
        "\n",
        "x = cutout(x_train[0])\n",
        "plt.imshow(x)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAV2klEQVR4nO3dX4xdV3XH8e+afx7/t8dOnME2df4C\nESROmEYpjRAFQQNCCkhVRB5QHhBGFZGKRB+iVCqp1AeoCognKtOkhIoSUiBKVKGWNIqUgtqAkzjO\nH7fBMYbYTOyYeOwZzzD2zKw+3GMxDmetub5z595J9u8jWb7ee84522fOuufevc7e29wdEXnz6+l2\nA0SkMxTsIoVQsIsUQsEuUggFu0ghFOwihehbzMZmdjPwNaAX+Ed3/+ICP78s8ny9SV12QswurLxR\nGVfNzMZ1Z5Ndlqg/qWvl9PckF0FPcgvMftdZFruVC7+V/Z2dhZk5r22ltZpnN7Ne4EXgg8Bh4GfA\nbe7+QrLNsgj29Und5uQiGAjq+lYkO0z299pYXHck2WWJtidBlr159waVa9fE26xeHdf198e3g6np\nmbCuPvwqPfX7PJPsbyaIpANjMHW2/miL+Rh/A3DA3Q+6+xngfuCWRexPRJbQYoJ9K/DyvH8frspE\nZBla1Hf2ZpjZLmDXUh9HRHKLCfYjwPZ5/95GzVdNd98N7Ibl851dpESL+Rj/M+BKM7vUzAaATwAP\nt6dZItJuLd/Z3X3GzO4A/oNGh+i97v5821q2hLKO0dNJOmwiqPMz8TaTybGyOjnf6eQz4cpku4mg\nQzvLhKxK6oy4hzy7rjKTwT7jI8UZiCxl23LqrRXL5WP8hqRuMKmLGp/9p1oN9rmkrkRDSV0W7NNB\nefKezqqkrsVHKlLRddBKsJ8EZrz9qTcReQNRsIsUQsEuUggFu0ghFOwihVjyJ+i6ZSCpy3pvsx7V\nqaD8t8k2WU991sZsnyXKfmdZBiXq0c7ucq30ggOsSS6eieRCiNJlWRvHg/Isi6M7u0ghFOwihVCw\nixRCwS5SCAW7SCHe0L3x2TtVNmfZRFKXPTMd9cZn7ViX1GUnX73x58syF9nvLDrH0TPzCx0r+11P\ntzjyI5rVLMsKtDJHoe7sIoVQsIsUQsEuUggFu0ghFOwihVCwixTiDZ16uyipy9IxWV020CGSpXGy\nE/yGPvkd1pvclqaS0R/RFFOtpj2j9Cvkg1BOJnWdoju7SCEU7CKFULCLFELBLlIIBbtIIRTsIoVY\nVPbHzA7RmA5rFphx95F2NOr1olFI2TtVNmdZNmIoS59Eg5qS1Z/SNJ9WfWnegRZPVjTq8OJkm2we\nwizNmo2mXA7aker9E3c/3ob9iMgS0sd4kUIsNtgd+JGZPWlmu9rRIBFZGov9GH+Tux8xs4uBR8zs\nf9398fk/UL0J6I1ApMsWdWd39yPV38eAB4Eban5mt7uPLFXnnYg0p+VgN7PVZrb23GvgQ8Bz7WqY\niLTXYj7GbwEeNLNz+/kXd//3VncWTboHsCYoz1IkmVZTK9E746Zkm9VJ3amkTpq3I6mLznE2N+T6\n5BY4naQA37SpN3c/CFzbxraIyBJS6k2kEAp2kUIo2EUKoWAXKYSCXaQQHZ3zsId4NFrWkCgtF00m\nCHkKLRv1tiGpa2XUW3asrP3SvPGkbjIoX5vtMEmvDSabtboeXXRdZSPzjiV1Ed3ZRQqhYBcphIJd\npBAKdpFCKNhFCmHu2ZCA9lph5luDumxZnainfibZppX9AfQnddE7Y3asrHc/68U/ktTJ4mXLfG1r\ncZ/Z7zObQi9abirr3Y+yWq8A0+61Y710ZxcphIJdpBAKdpFCKNhFCqFgFymEgl2kEB0dCNPXCxuD\nEQgbo/wD0BO8JY1FoxzIB6Bk73CtLP8UzZG3UDuUXuuebGBKq3MbZmnbLMEdbZellqP9ZcfRnV2k\nEAp2kUIo2EUKoWAXKYSCXaQQCnaRQiyYejOze4GPAsfc/Z1V2RDwXRor7xwCbnX3E00dMXh7sSxv\nEViRtH5VkrfI/tPZu1+URluRrF11PJsMT5r2p8Pxb+YXo3HC9MWgPLsGsvRVlg7Lrp3s8o5an6WB\no/RgljZs5s7+TeDm15XdCTzq7lcCj1b/FpFlbMFgr9Zbf+11xbcA91Wv7wM+1uZ2iUibtfqdfYu7\nj1avX6GxoquILGOLflzW3d3Mwq85ZrYL2AUwoO5Aka5pNfyOmtkwQPV3OGe9u+929xF3H+lr9aFj\nEVm0VoP9YeD26vXtwEPtaY6ILJVmUm/fAd4HbDazw8AXgC8CD5jZp4BfArc2c7A5h6lgdJtlw8MC\np5M8SDb5X5Y+mUjqomWG3pKk17I0TpKxS5evKtFlV20M69Zt/E1Yd+KFoDw5ViuTjkI+wjFLo0Uj\n8LJjtTLqbcFgd/fbgqoPLLStiCwf6jITKYSCXaQQCnaRQijYRQqhYBcpREcnnHRgNniwxpMZAKPl\n6FYmD+msSfInv07yclF6LfNqUpelYy5L6g620I43s1fH4vTakdGwKkyjZWvwZWv3Zamt7JmxLPUW\n3XGz/WUTZl7ocUTkTUbBLlIIBbtIIRTsIoVQsIsUQsEuUoiOpt56e2FDkPOYSVoyEQxFy9J1J5P0\nWnMzYzYvS6/1JnVbk7fag1mupkBrhuJc6rbVcd3a0foFAcfjTB7HTsV12e86Wa4wtTooz0ZuRv/j\nxU44KSJvAgp2kUIo2EUKoWAXKYSCXaQQHe2Nn5uF8bGgIUnXY38La930ZSMWWhQdLjvUxUnd1mtW\nxpV7s+EY5bn87TvDurHZeDa//mvq566bGotHz/zkh3vCusNJT32WeclEv+ms5z+6S2fXou7sIoVQ\nsIsUQsEuUggFu0ghFOwihVCwixSimeWf7gU+Chxz93dWZXcDn+Z306/d5e4/bOaAvUH+ajbJM0Tp\nhOydqpU5uhYStSNJoPGHVw+EddvedmO84d7HmmpTKY6Px4mtDRddGtZtumRHbfnUxLpwm551cept\nNkm9ZYNQsjRaC5nlcAmzxabevgncXFP+VXffWf1pKtBFpHsWDHZ3fxx4rQNtEZEltJjv7HeY2T4z\nu9fM4iU2RWRZaDXYvw5cDuwERoEvRz9oZrvMbI+Z7ZldgkdYRaQ5LQW7ux9191l3nwO+AdyQ/Oxu\ndx9x95Goc05Ell5LwW5mw/P++XHgufY0R0SWSjOpt+8A7wM2m9lh4AvA+8xsJ42e/kPAZ5o5mAEW\nfJTPUmXRB4Ks8UvxjWEwKL8+6bF4x3vi9NqJY8HkevJ7HvvJ/4R177kxHjK56ZJNteWnxo+F2/Sv\nituxeUtcN5fcOmeTUZ0z0/XlJ5PLI9gkXWZqwWB399tqiu9ZaDsRWV70BJ1IIRTsIoVQsIsUQsEu\nUggFu0ghOjrhpDvMBcN1sukVo3FjWeNbnfwv2+eOoPzam64Itxl+2zVh3d7//qem2iSweXP8RNbL\nv346rNsyvLW2fGYyzmt5cjHa6bgue0LUkwfKVgbzZQ4kF/Gpk/Xl2ZJRurOLFELBLlIIBbtIIRTs\nIoVQsIsUQsEuUoiOpt7MoD9IJ5xItotGxGUTPWapt6GkLpt/6/LrL6st3/auuin6zomHxJ0dT/I4\ncp5rrorTmzO9q8O6/t4N9eUD8RSQfb+N25Fk7NIRZ9EEkQATwT5XJem6LZfUl588Hm+jO7tIIRTs\nIoVQsIsUQsEuUggFu0ghOjsQZg6mg0EGybRf4Rx0/dmxkrqsF/+6d8TLNb3nwx+oLV+XTEx29OD+\nsK5Xb7VNOzURd01f9a53xxvO1o8yeW3scLjJZNIbn2WNssmTk13GdclFfEUwCd1cso0uN5FCKNhF\nCqFgFymEgl2kEAp2kUIo2EUK0czyT9uBbwFbaCQDdrv718xsCPgujanZDgG3unuWmcDJUwNhG4Ly\nbHBBlgaJlnEC2PnuOI2zor8+2ffC3ngOtBO/fimsm47W8JHf8/IvfpXUPh/WTEyM15YP9sUX4kww\nJxzAyfrdAXkqOEstR6ng5FDMBKNusvBq5s4+A3ze3a8GbgQ+a2ZXA3cCj7r7lcCj1b9FZJlaMNjd\nfdTdn6pejwP7ga3ALcB91Y/dB3xsqRopIot3Qd/ZzWwHcB3wBLDF3UerqldofMwXkWWq6cdlzWwN\n8H3gc+5+yux334rd3c3qF2M2s13Args6mIi0XVN3djPrpxHo33b3H1TFR81suKofBmoXvHb33e4+\n4u4jrS7cICKLt2CwW+MWfg+w392/Mq/qYeD26vXtwEPtb56ItIu557kwM7sJ+C/gWX43zdZdNL63\nPwC8FfgljdRbNoUbg2a+I6jLNozGoUVz0wHEM4zBW9cm2yU5u6Et62rLLx7eHm5zZjJYpwc4fSwe\nefVolmkq0I6kbk08UJHpKD+b5Mlmk1vgkWydsiRltyqpGwzSaNnozHcEq4r9+BkYm6hfbGrBr9Hu\n/mPitHX9mE8RWXb0BJ1IIRTsIoVQsIsUQsEuUggFu0ghOv5QW7RETpI9SUepRbKE4tyZuO54MhJt\n4tSp2vKVZ+NRV3PJQlRDG+tTeQD8qv5YpRpMUqKzye8zupudSn7Pye5Ye3FcdzrJlY0na0P9NlgF\nbFNyeWwO2tGXpBR1ZxcphIJdpBAKdpFCKNhFCqFgFymEgl2kEB1PvUXvLll6LUqjrU62WZ2kICaT\nIXGbkn1GJ+tMPLCNuZ54bN5kfzaloMw3k+RSf5Fsl42MjGSTlW7dENedSdo4dTyumwkWe1u9Ndnf\nZH35XJLi051dpBAKdpFCKNhFCqFgFymEgl2kEB3tje8BBoJxIZNJt2k0lCTpeEx73HuTnvoVyYic\nYPUnBpK1fdaviwfCvPJqK33FZRpN6tp9Fi9K5ii0oOccwJKJFFdOxHVbN9aXb0t6/g+8UF8+ncyR\npzu7SCEU7CKFULCLFELBLlIIBbtIIRTsIoVYMPVmZtuBb9FYktmB3e7+NTO7G/g08Gr1o3e5+w/T\ng/XBls31dWdfibeLsgnB1F1APgddX5KWW5dsOBCk3qaShqzsTxJD2WRncp41SV1wSQHx3HUzySqj\ns8n1MfVyXNeTXDvJ1HVcd1WwzYY4p/vkaP1ImJnkcmsmzz4DfN7dnzKztcCTZvZIVfdVd//7JvYh\nIl3WzFpvo1TPNLj7uJntB5LBdyKyHF3Qd3Yz2wFcR2MFV4A7zGyfmd1rZsFzQCKyHDQd7Ga2Bvg+\n8Dl3PwV8Hbgc2Enjzv/lYLtdZrbHzPaczZ5vFZEl1VSwm1k/jUD/trv/AMDdj7r7rLvPAd8Abqjb\n1t13u/uIu4/0q+9fpGsWDD8zM+AeYL+7f2Ve+fC8H/s48Fz7myci7dJMb/wfA58EnjWzvVXZXcBt\nZraTRpbrEPCZhXY0MABv3V5ftz6Z+OtAMOTpaHKsLKuVpXFOz8R1s0GKLcni8NpYXKcZ6Jq3LRmN\nGI2kBJiOLoTkyj+dLQ2VpNeyORGvSLq033JJ/T335cPBRHPAb4IUW3L5NtUb/2Pq5+BLc+oisrzo\nW7RIIRTsIoVQsIsUQsEuUggFu0ghOjrhZG8frAseqp16tb4cYONQUJGMNjuepE+SOQPTE3ImeAIw\nezAwGUBFsmqUvM7xJJeapVItSOlakqMaSC6CFckvNEsB7rgirpuarM/nPf5kvE0raVvd2UUKoWAX\nKYSCXaQQCnaRQijYRQqhYBcpREdTb2bQN1hfN7gu3m4oyK30Jeta9f8mrjuVjETLrAzO1mwyyd9s\nNoFla80oUja5aHIZsD44/33J76UniYpsDcGjyXVwIlnrbfx0fWOOx5u0RHd2kUIo2EUKoWAXKYSC\nXaQQCnaRQijYRQrR0dTb3BxMRCmIZMTQmmAmv/6V8TarV8R169fHdROnLrxuIknjZKPe1iZ1x5K6\nEiWZWV5L6qLRYeuSNNlkUpdNcpp5+qm4bsu2Fnd6gXRnFymEgl2kEAp2kUIo2EUKoWAXKcSCvfFm\nNgg8Dqyofv577v4FM7sUuB/YBDwJfNLds1WXOHMGDv+yvm46GZyy9qL68sGkN359MjHZUDSnHTCR\njLgYC9p4Ihl0cyLp3c+WjZLzJR3kaV10WWUXata736ps2ahLouzQy+1tQzN39mng/e5+LY3lmW82\nsxuBLwFfdfcrgBPAp9rbNBFppwWD3RvOZcf7qz8OvB/4XlV+H/CxJWmhiLRFs+uz91YruB4DHgFe\nAsbc/dyEvIeBZJ1KEem2poLd3WfdfSewDbgBeHuzBzCzXWa2x8z2nMm+XInIkrqg3nh3HwMeA/4I\n2GBm5zr4tgFHgm12u/uIu49kk+iLyNJaMNjN7CIz21C9Xgl8ENhPI+j/rPqx24GHlqqRIrJ4zQyE\nGQbuM7NeGm8OD7j7v5nZC8D9Zva3wNPAPQvtyK2H2f5VtXVnB+JJuqaD9ZV6kiV8BpPBLhuCVB7A\nxuTtb2iyvnwsydWMJROJTSVpvhcPx3UlSrKs6WCjaDxUMBUiABuSuhanL+RtyfJPO66or7z2VwfC\nbQ4HKd2sfQsGu7vvA66rKT9I4/u7iLwB6Ak6kUIo2EUKoWAXKYSCXaQQCnaRQph7Mhyn3QczexU4\nN+5tM+1f4aYVasf51I7zvdHa8QfuXptc7miwn3dgsz3uPtKVg6sdakeB7dDHeJFCKNhFCtHNYN/d\nxWPPp3acT+0435umHV37zi4inaWP8SKF6Eqwm9nNZvZ/ZnbAzO7sRhuqdhwys2fNbK+Z7engce81\ns2Nm9ty8siEze8TMfl79vbFL7bjbzI5U52SvmX2kA+3YbmaPmdkLZva8mf1FVd7Rc5K0o6PnxMwG\nzeynZvZM1Y6/qcovNbMnqrj5rpkNXNCO3b2jf2hMqvoScBkwADwDXN3pdlRtOQRs7sJx3wtcDzw3\nr+zvgDur13cCX+pSO+4G/rLD52MYuL56vRZ4Ebi60+ckaUdHzwlgwJrqdT/wBHAj8ADwiar8H4A/\nv5D9duPOfgNwwN0PemPq6fuBW7rQjq5x98f5/RmLb6ExcSd0aALPoB0d5+6j7v5U9XqcxuQoW+nw\nOUna0VHe0PZJXrsR7Fs5f0bsbk5W6cCPzOxJM9vVpTacs8XdR6vXrwBbutiWO8xsX/Uxf8m/Tsxn\nZjtozJ/wBF08J69rB3T4nCzFJK+ld9Dd5O7XAx8GPmtm7+12g6Dxzk7jjagbvg5cTmONgFHgy506\nsJmtAb4PfM7dz5uLpZPnpKYdHT8nvohJXiPdCPYjwPZ5/w4nq1xq7n6k+vsY8CDdnXnnqJkNA1R/\nd2WJdnc/Wl1oc8A36NA5MbN+GgH2bXf/QVXc8XNS145unZPq2Bc8yWukG8H+M+DKqmdxAPgE8HCn\nG2Fmq81s7bnXwIeA5/KtltTDNCbuhC5O4HkuuCofpwPnxMyMxhyG+939K/OqOnpOonZ0+pws2SSv\nnephfF1v40do9HS+BPxVl9pwGY1MwDPA851sB/AdGh8Hz9L47vUpGmvmPQr8HPhPYKhL7fhn4Flg\nH41gG+5AO26i8RF9H7C3+vORTp+TpB0dPSfANTQmcd1H443lr+ddsz8FDgD/Cqy4kP3qCTqRQpTe\nQSdSDAW7SCEU7CKFULCLFELBLlIIBbtIIRTsIoVQsIsU4v8BOuBsmsFX3mEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0743NwHU1eSe",
        "colab_type": "code",
        "outputId": "4d94832e-2080-4af7-cfe1-50aca0a41824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        preprocessing_function= cutout)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6CID1kL1s8c",
        "colab_type": "code",
        "outputId": "0696fe88-0a57-4a25-96ac-ea4f1ad117d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                      \n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 84s 54ms/step - loss: 0.8807 - acc: 0.7404 - val_loss: 0.6411 - val_acc: 0.8448\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.54452\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.8058 - acc: 0.7671 - val_loss: 0.6114 - val_acc: 0.8534\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.54452\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 84s 54ms/step - loss: 0.7837 - acc: 0.7748 - val_loss: 0.6104 - val_acc: 0.8519\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.54452\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.7780 - acc: 0.7777 - val_loss: 0.6047 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.54452\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 84s 54ms/step - loss: 0.7622 - acc: 0.7841 - val_loss: 0.6016 - val_acc: 0.8599\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.54452\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.7521 - acc: 0.7865 - val_loss: 0.6133 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.54452\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.7479 - acc: 0.7894 - val_loss: 0.6013 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.54452\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 84s 53ms/step - loss: 0.7422 - acc: 0.7883 - val_loss: 0.6223 - val_acc: 0.8475\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.54452\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.7368 - acc: 0.7900 - val_loss: 0.5743 - val_acc: 0.8585\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.54452\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.7331 - acc: 0.7924 - val_loss: 0.5951 - val_acc: 0.8546\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.54452\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.7325 - acc: 0.7916 - val_loss: 0.6030 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.54452\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.7257 - acc: 0.7926 - val_loss: 0.5897 - val_acc: 0.8501\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.54452\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.7253 - acc: 0.7927 - val_loss: 0.5972 - val_acc: 0.8552\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.54452\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 84s 54ms/step - loss: 0.7155 - acc: 0.7976 - val_loss: 0.5698 - val_acc: 0.8589\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.54452\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 84s 54ms/step - loss: 0.7157 - acc: 0.7961 - val_loss: 0.5789 - val_acc: 0.8582\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.54452\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 84s 53ms/step - loss: 0.7092 - acc: 0.7974 - val_loss: 0.6164 - val_acc: 0.8509\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.54452\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.7074 - acc: 0.7999 - val_loss: 0.5839 - val_acc: 0.8519\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.54452\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.7051 - acc: 0.7991 - val_loss: 0.5975 - val_acc: 0.8509\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.54452\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.7053 - acc: 0.7997 - val_loss: 0.5558 - val_acc: 0.8622\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.54452\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.6956 - acc: 0.8034 - val_loss: 0.6038 - val_acc: 0.8523\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.54452\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.6966 - acc: 0.8028 - val_loss: 0.5574 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.54452\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.7012 - acc: 0.8003 - val_loss: 0.5966 - val_acc: 0.8526\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.54452\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.7001 - acc: 0.8006 - val_loss: 0.5916 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.54452\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 84s 54ms/step - loss: 0.6933 - acc: 0.8041 - val_loss: 0.5554 - val_acc: 0.8636\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.54452\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.6892 - acc: 0.8036 - val_loss: 0.5543 - val_acc: 0.8607\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.54452\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 84s 54ms/step - loss: 0.6899 - acc: 0.8044 - val_loss: 0.5577 - val_acc: 0.8656\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.54452\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.6916 - acc: 0.8037 - val_loss: 0.5695 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.54452\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 82s 53ms/step - loss: 0.6888 - acc: 0.8040 - val_loss: 0.5646 - val_acc: 0.8634\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.54452\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 81s 52ms/step - loss: 0.6839 - acc: 0.8059 - val_loss: 0.5668 - val_acc: 0.8587\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.54452\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 82s 53ms/step - loss: 0.6858 - acc: 0.8059 - val_loss: 0.5810 - val_acc: 0.8563\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.54452\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 82s 53ms/step - loss: 0.6537 - acc: 0.8187 - val_loss: 0.5182 - val_acc: 0.8754\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.54452 to 0.51822, saving model to /content/saved_models/cifar10_resnet_model.h5\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.6324 - acc: 0.8225 - val_loss: 0.4993 - val_acc: 0.8791\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.51822 to 0.49926, saving model to /content/saved_models/cifar10_resnet_model.h5\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 82s 53ms/step - loss: 0.6258 - acc: 0.8249 - val_loss: 0.4894 - val_acc: 0.8835\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.49926 to 0.48944, saving model to /content/saved_models/cifar10_resnet_model.h5\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.6245 - acc: 0.8249 - val_loss: 0.5123 - val_acc: 0.8783\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.48944\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.6207 - acc: 0.8277 - val_loss: 0.4835 - val_acc: 0.8857\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.48944 to 0.48354, saving model to /content/saved_models/cifar10_resnet_model.h5\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 82s 53ms/step - loss: 0.6151 - acc: 0.8297 - val_loss: 0.4924 - val_acc: 0.8806\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.48354\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.6108 - acc: 0.8301 - val_loss: 0.4845 - val_acc: 0.8855\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.48354\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.6136 - acc: 0.8287 - val_loss: 0.4932 - val_acc: 0.8838\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.48354\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.6031 - acc: 0.8306 - val_loss: 0.4924 - val_acc: 0.8831\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.48354\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 83s 53ms/step - loss: 0.6016 - acc: 0.8325 - val_loss: 0.4907 - val_acc: 0.8830\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.48354\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 82s 53ms/step - loss: 0.5955 - acc: 0.8334 - val_loss: 0.4807 - val_acc: 0.8861\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.48354 to 0.48067, saving model to /content/saved_models/cifar10_resnet_model.h5\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 82s 52ms/step - loss: 0.5932 - acc: 0.8349 - val_loss: 0.4806 - val_acc: 0.8844\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.48067 to 0.48059, saving model to /content/saved_models/cifar10_resnet_model.h5\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 82s 52ms/step - loss: 0.5833 - acc: 0.8383 - val_loss: 0.4756 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.48059 to 0.47561, saving model to /content/saved_models/cifar10_resnet_model.h5\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 82s 52ms/step - loss: 0.5824 - acc: 0.8378 - val_loss: 0.4808 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.47561\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 82s 52ms/step - loss: 0.5789 - acc: 0.8404 - val_loss: 0.4772 - val_acc: 0.8877\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.47561\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 82s 52ms/step - loss: 0.5859 - acc: 0.8368 - val_loss: 0.4777 - val_acc: 0.8893\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.47561\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 82s 52ms/step - loss: 0.5857 - acc: 0.8363 - val_loss: 0.4761 - val_acc: 0.8877\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.47561\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 82s 52ms/step - loss: 0.5800 - acc: 0.8388 - val_loss: 0.4801 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.47561\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 82s 52ms/step - loss: 0.5724 - acc: 0.8412 - val_loss: 0.4741 - val_acc: 0.8887\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.47561 to 0.47412, saving model to /content/saved_models/cifar10_resnet_model.h5\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 82s 52ms/step - loss: 0.5693 - acc: 0.8413 - val_loss: 0.4742 - val_acc: 0.8884\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.47412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f284ed1fe80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngwHG5d51jI0",
        "colab_type": "code",
        "outputId": "e73a8e27-8e54-4c96-95ea-10614c1dbf5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 216us/step\n",
            "Test loss: 0.47415243117809297\n",
            "Test accuracy: 0.8884\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}